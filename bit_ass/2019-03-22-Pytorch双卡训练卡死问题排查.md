---
layout: default
---
# Pytorch双卡训练卡死问题排查

 [*Link:*](https://zhuanlan.zhihu.com/p/60054075)

这还是年前倒腾自己的机器，都2019年3月份了，整理下。

  


## 现象  
  
自己的私人珍藏机器，之前用双卡训练总会出现卡死的问题。不过反正也不影响打游戏，嗯，或者，单卡训练。所以又不是不能用。  
我印象里都是时不时出现的，现在（2018年，时间线有点乱）好了，目前的状态是100%空手接卡死。I'm angry，现在只能硬着头皮看看问题了。

## 流程  
  
以下是排查流水账  


1. **换后端**  
首先肯定是换后端看看，gloo就是纵享丝滑。NCCL就是，我忘了现象了，反正是卡死，时不时还彻底卡死到只能重启。
2. **查拓扑**  
之后就用CUDA的工具查拓扑，看着没什么问题，呵呵，实际上是有问题我也看不出来。
3. **测P2P带宽**  
测了p2p的带宽，惊呆了，就快赶上机械硬盘的带宽了。
4. **解决**  
由于之前定位到换NCCL就会卡死，所以我顺路把NCCL的文档看了。谢天谢地，刚好知道可以用环境变量禁用p2p通讯。试了试，嗯，起码是跑起来了。

文档地址在下面：

[Environment Variables](https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html#nccl-p2p-disable)事实上有另外一个变量可选level，我当时都试了下，都可以避开卡死。

## 原因猜测  
整个流程其实是充满了血泪的，我只是现在回忆起来，剩下的都是美好。作为一个合格的码畜，我肯定少不了的查github和stackoverflow，看到的是大量的相关issue。

* 最先怀疑的是CPU的PCIe接口不够造成的。
* 后来发现，各种CPU都有这个问题。
* 现在，只能**怀疑是主板在PCIe接口的设计有问题**。我的主板双卡的话，给显卡的PCIe的接口是减半的（单卡X16的话，双卡就是每个X8）。同时，测的p2p的带宽，感觉就是只用了X1做通讯，如果真是这样，我是应该感谢主板成功做到了理论带宽么？

## 其他补充  
* 我的私人珍藏用的还是1080Ti，然而新的2080Ti已经有NVLink了。
* 一张卡的话，现在一般平均得分8个核，起码也得四个。否则容易喂不饱GPU，尤其是现在新卡都可以支持混合精度训练。
* 四卡及其以上，上水冷。或者，放在空调出风口对着吹？
* 虽然这篇文章很老了，不过看一看还是有参考意义的：

[https://blog.exxactcorp.com/exploring-the-complexities-of-pcie-connectivity-and-peer-to-peer-communication/](https://blog.exxactcorp.com/exploring-the-complexities-of-pcie-connectivity-and-peer-to-peer-communication/)* 这是一个私人配工作站的文章，有矿。我只能说，要不起。不过看了带宽，12和34的瓶颈还是很明显的，可惜也没有4-way的NVLink：

[刘留：打造水冷四张RTX 2080Ti的深度学习工作站](https://zhuanlan.zhihu.com/p/56701258)* 有倒也是有，：

[NVIDIA NVLink Fabric: Advanced Multi-GPU Processing](https://www.nvidia.com/en-us/data-center/nvlink/)## 私人单机吞吐量估计  
1. 确认显存和batch size，比如res18，1080Ti可以设置batch size 256，使用半精度就是512.
2. 预估显卡batch处理速度，比如ImageNet，那就随机一个[256，3，224，224]的tensor，跑一个forward。时间double，基本就是训练速度。（或者直接跑一个foward+backward），比如说是.5秒。
3. 确认卡数，比如双卡，那么就是需要支撑每秒 256 / 0.5 \* 2 = 1024张图片的CPU和IO。
4. 数据集不大的，会都载入内存缓存的，这样IO基本可以忽略。大的，估计估计SSD持续读得要多快，要几块。
5. 有钱人不做选择题，选最好的就可以。

