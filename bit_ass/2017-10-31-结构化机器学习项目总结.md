---
layout: default
---
# 《结构化机器学习项目》总结

 [*Link:*](https://zhuanlan.zhihu.com/p/30610168)

应该是上上周花了一天看了下Andrew的DL课程，不过只是第三部分：结构化机器学习项目。后面又抽空重新快速过了一遍，细节上肯定会有很多遗漏，重新结合自己的思考总结一下。本来应该很早就整理了，笔记的东西都放那里半个多月了，不过这两周又是出差又是写文档，一直拖延着。其他的课程没看就不涉及，第三部分内容不是很复杂，主要是指导性的，同时对自己也有一定启发。

  


## 1. 重视与实际应用场景的结合  
主要谈的是机器学习项目在实际应用中如何获得更好的表现，基本的原则就是：尽量贴合实际应用场景。首先是训练过程中教科书般的分配：训练、验证、测试集合。不过在实际中，还存在一个问题，就是数据集合的分布问题，虽然可能不能保证三者的分布完全一致，但是基本的原则是三个集合的分布要符合自己应用需要解决的问题的要求。最起码的，测试集合必须符合实际场景，这样哪怕训练出了问题，但是在测试这块就能觉察出来。之后，就需要考虑训练集合与验证集合的数据尽量符合实际场景，数据集合不足的时候可以训练集合中加入一些非实际应用场景的数据作为辅助，依靠后面符合实际场景的验证、测试集合来评价最终的模型效果。

  


对于评价指标，依然是需要一个可以最终评价实际应用场景的指标。实际应用很少是一个单纯的分类准确率就可以评价的，虽然训练过程中还是会依靠优化Loss函数实现，但是验证集合上的评价应该还是要符合实际应用的需求。比如，即使最单纯的分类，实际应用中可能还会对不同的类别有不同的精度要求，那么准确率计算的时候，就需要考虑好各类的权重。或者是图像分割的任务，实际场景可能必须要保证某一些类别的分割的准度，其他的类别可能有个大概边界也没问题，那么不管是考虑Loss还是考虑验证集合的指标，都要把这个因素考虑进去。这个里面也提了硬性指标，硬性指标起码在我接触的来看主要就是性能问题，目前我们的性能硬性要求就是30FPS，包括GPU和CPU PC上，目前嵌入式实在做不到。

  


## 2. 处理Bias与Variance的平衡  
bias与variance的考虑，其实就是判断模型的拟合能力以及防止过拟合的平衡。考虑模型规模是否达到数据集本身拟合的极限，靠的是模型与贝叶斯误差的差距，理想误差我们并不能直接获得，所以可以假设人类能够达到的最佳水平接近贝叶斯误差。只要接近人类、甚至超越人类的水平就可以基本认为模型的拟合能力基本接近数据集的极限。

  


当然，假设人类最佳表现接近理想误差的前提应该限制在简单任务、非结构化数据上。因为，人类主要的优势还是在非结构化数据的理解上，以及非常复杂的推理、归纳上。结构化数据上机器实现超越人类表现的难度还是比较低的。最近比较明显的就是AlphaGo的新老版本都很快的实现超越人类最佳表现，主要就是：第一，棋盘是一个很容易处理的结构化数据；第二，这个任务还是相对比较容易从数学上定义的，没有非常复杂的推理、归纳。

  


由于存在Unavoidable bias，所以一旦bias已经接近已知的理想状态就要开始考虑处理过拟合的问题了。这个工程的时候更加需要考虑下，以免浪费太多精力在没有意义的事情上。

  


对于封闭测试是否可以提供贝叶斯误差的问题，我的想法是还需要考虑任务与网络的复杂度问题。*Understanding deep learning requires rethinking generalization*这个里面出现了网络可以强行记忆数据集的问题，如果一个任务难度比较小，同时又使用了一个很复杂的结构，那么利用封闭测试获得的准确率可能只是强行记忆的结果，不能代表这个网络本身在任务上的推理能力。

  


## 3. 重视错误分析与网络诊断  
这些其实都是些dirty work，谁也不愿意把数据集自己亲身过一遍。由于错误案例未必错误，正确案例未必正确，数据集不多的情况下，可能还需要直接扫一遍训练集，或者抽样一部分出来看。Andrew的分析表格比较有意思，这样可以更加量化具体问题的权重，要学习一个。自己只是简单估计个数目，没有这样一个个打勾的。

  


网络诊断问题上，我的观点是网络本身就是统计学习的，诊断的结果也应该是统计角度上来看，比如可以看梯度传递的分布情况，梯度是否能够传递到网络输入层，不同层梯度的衰减情况，不同的梯度可不可以利用不同的学习率来调整。是否需要理解具体的网络权重的意义或者是卷积是否符合自己的标准，这样的问题反倒不重要，毕竟网络内部有其自己的逻辑，和人类直觉不一样也很正常，最后训练结果满足应用要求才是最关键的。

  


上面的诊断与分析都是相对搭建网络、换模型来说比较脏的活，人性的角度来说没人愿意做，所以提供一个良好的UI接口才是关键。我的考虑，这个系统需要包括的是：

* 基本的学习曲线展示。
* 学习过程中实时/准实时的梯度传递情况。
* 网络权值的分布情况。
* 每一层的中间结果的分布与展示。
* 数据案例抽样展示（包括正确的、错误的、低置信度等等的结果）。
* 提供快速的模型替换与结构微调操作。
* 方便的细粒度的试验操作，比如锁定、调整权值。
* 针对数据集的统计信息展示，比如类别的分布、图片数据的各通道的分布。
* 对硬件、网络、存储的隐藏。
* 方便的扩展接口，训练人员可以快速脚本直接操作网络。

  


## 4. 多任务与端到端学习  
多任务学习我的经验只限于：

1. 需要注意处理好loss之间的平衡
2. 尤其要保证任务之间的loss都保持在一个数量级上，或者最重要的任务的loss占据主导地位。
3. 一般来说分类任务是最好训练的，可以考虑先着重分类任务形成特征，之后调整其他任务loss的权重。

  


对于端到端学习我们只是尝试了在模拟环境下利用车辆前视图像学习方向盘角度，虽然有效果，不过刚刚起步，还需要增加数据量进行新的验证，角度目前也难以保持平滑。油门由于没有加入速度的输入也没有利用多帧数据，所以没有办法直接提供对速度的控制。

  


  


  


  


今天刚刚看到的一份综述文档，目前只是看了目录，看样子不错：

[https://arxiv.org/pdf/1703.09039.pdf](https://arxiv.org/pdf/1703.09039.pdf)

