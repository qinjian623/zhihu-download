---
layout: default
---
# YOLO训练中的问题与怀疑

 [*Link:*](https://zhuanlan.zhihu.com/p/58188673)

最近用YOLO训练过程中遇到的问题和猜测。

## 收敛速度比较慢  
YOLO的训练比较明显的一个现象就是收敛比较慢，YOLO训练可以看作是是三个任务的联合训练，分别是：Objectness[O]，一个BinaryCrossEntropy训练或者Logistic regression；Boundbox[B]，一个数值回归的训练；Classification[C]任务，多类的分类任务，其实也是BCE。起码目前我观察的现象：

1. O的训练：首先网络会被训练到基本都是100%的输出接近于0，后续才慢慢的收敛到接近GroundTruth。
2. 同时，由于在训练过程中，B和C的任务只训练GT中objectness应该为1的点，一张图中，非目标区域的都是不参与训练的。
3. 由于O任务的训练的收敛速度较慢，在O收敛的比较好之前，B和C的任务很难进一步学习。

**O的收敛**

其中1的问题，还是FocalLoss期望解决的问题，那就是正反案例的极度不平衡的问题。造成初期大量的负样例将整个O的输出推到了接近0的位置上。后续的训练才会慢慢的调整，让正样例能够准确预测。

这一过程，会浪费了不少算力。怎样让网络更加有效的训练？我能想到的是：

1. Loss的计算加入类似FocalLoss的方法，让训练更加倾向于那些预测比较偏离的案例。当然原文已经试过了这个手段，但是是不是需要更加有针对性的调整？类似的试验我也进行过，但是目前也没有很明确的结论。
2. 采用一些针对性的采样手段，我目前知道的比如SNIPER，让训练过程在采样阶段就忽略掉作用不大的图像区域，集中算力训练难度较大的。

**BC任务**

BC任务需要等待O的训练问题，第一直觉应该是加大BC在整体loss上的比重，让他们可以早点快速学习。同时，带来的问题是，可能会对O的训练有负面影响。不过这样的方法也只是在训练中多了个人肉调参的手段，是否有更加根本的解决方法？



---

## XYWH尺度不一致  
由于XY在YOLO用通过Sigmoid函数做了限制，然而WH的预测没有。这样的情况是，这两者的尺度不是一个量级的，那么在Loss中的比例，也就不可避免的有了倾向性。当然，随着训练的继续，两者的Loss会慢慢的接近。但是，这个问题和前一点中BC需要等待O训练是一个性质。直觉上看，应该也会拖慢收敛速度，或者起码，两个任务的收敛不是在一个步调上。

这样尺度不一致的问题，可以通过选择更加合理的anchors来缓解。让训练集的目标框的大小更加和anchors贴近，会缩小WH的尺度，整体上XYWH的预测范围会更加接近。

同时WH的预测在目标框小于和大于对应anchor的两个区间的尺度的变化速度是不一致的，这是ln函数的特性造成的。我的怀疑是，这个特性，会不会给网络的训练带来负面影响？



---

## XY的Sigmoid先验  
由于Sigmoid的特性，在极值附近和中间值附近的训练难度是完全不一样的，那么我们可以想象，对目标中心位置的预测的难度是越靠近边缘越大的。  
这样的一个先验的限制，是不符合数据集合分布的，目标出现的位置应该是比较平均的。



---

## Anchor数量  
Anchor的数量选择会带来一个平衡问题。需要根据具体的数据集来确定：

* 一个目标框大小变化不大的数据集，比较多的anchors会让B任务的训练数据分散，造成每个anchor的预测得不到充分的训练；不如少点anchors，让每个anchor都分配更多的数据来训练。
* 变化较大的数据集，如果anchors数量太少，没法控制好WH的预测范围。训练过程中，偶尔的一个错误，会让B的loss变得太大（尤其是用MSE这种对outlier比较敏感的loss）破坏原本稳定的训练。



---

## “单点确认”可能会降低召回  
YOLO的O任务是针对目标中心点的，这也是因为B任务中XY只负责预测对应grid里的中心位置。  
不过这样的限制显得过于严格了，网络未必可以确认feature map中哪个位置对应目标的正中，在feature map尺寸比较大的情况下，这个问题会更加明显一些。

另外一种情况是，目标框的中心点并不是图中目标的中心点：比如单手展开的行人，标注的目标框的中心点往往都已经不在目标主体上了。这个也会在训练的过程中给网络带来一些混淆。

