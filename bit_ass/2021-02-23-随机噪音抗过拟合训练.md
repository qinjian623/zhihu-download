---
layout: default
---
# 随机噪音抗过拟合训练

 [*Link:*](https://zhuanlan.zhihu.com/p/352212603)

 春节没事干，顺着 

[Captain Jack：DNN 特性与抗过拟合思路](https://zhuanlan.zhihu.com/p/343963913)随机噪音的内容做的玩具。

  


**玩具地址：**

[https://github.com/qinjian623/pytorch\_toys/tree/master/overfit/main.py](https://github.com/qinjian623/pytorch\_toys/tree/master/overfit/main.py)只拿 CIFAR10 简单做了测试。私人的话，ImageNet需要掏钱租机器，实在玩不起。测试方法大约等效 featmap 加噪音（但是考虑到了conv的语义）。 

  


**测试结果：**



| HP Setting | baseline | with Noise(anchor=True) |
| --- | --- | --- |
| no aug | 74.74 | 79.81 |
| aug | 79.67/79.66/79.35 | 82.84/82.84/82.90 |
| aug | 79.41 | 82.50 |
| aug, ood test | 67.65 | 76.38 |
| strong aug, schedule x2 | 87.72 | 86.29 |
| aug, multi-layer dropout[0.3] | 78.15 |  |

这个方法实际上属于数据增强，所以随着使用数据增强手段的增多，边际效用是递减的（strong aug 情况下，schedule x2 也没更好）。 

有些数据集比较丰富的任务，其实不怎么鼓励太过分的数据增强，毕竟也只是人工的扩充一些数据，并不能完全模拟自然数据，太多了有可能学偏，而且训练的epoch还要相应的增加。 

