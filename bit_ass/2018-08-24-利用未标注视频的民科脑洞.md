---
layout: default
---
# 利用未标注视频的民科脑洞

 [*Link:*](https://zhuanlan.zhihu.com/p/42878272)

一般情况下，未标注数据肯定会远远大于标注数据。

攒的满满的一盘视频，是否能够利用起来优化网络显然就是一个值得考虑的东西。毕竟这些数据相比数据增强的方法，都是实实在在的真实数据，而且，也可以再用数据增强啊。

自己的一个民科脑洞就是：类似训练语言模型的方法，让网络训练N-gram的视频模型。

## 自己觉得需要预先考虑的几点  
  
1. **网络需要预训练好，否则八成八会训练成只关注底层像素级的内容。**

这个情况不要太常见，从零开始训练的网络，会针对优化目标投机取巧，这样的预测模型只需要像素相关性就可以完成的不错，所以我猜测网络会很快奔着只看像素去，抽象概念完全学不到。

从让网络掌握概念的角度来说，分类任务绝对是目前最高效的方法。所以目前来说，我的基本思路都是：先上分类数据预训练一个模型，数据越多越好。

  


**2. 预测目标可能不能单纯是下一帧。**

因为太强相关了，最后的结果就如上点一样，八成八学的都是底层信息。

可以考虑我们搞一个Skip-frame训练法，预测的是后续第N帧的图片，呵呵呵，或者multi-skip-frame训练法，然后可以多接几个输出，同时预测未来N, M...的图片。 

  


**3. 输出目标**

显然，我们不需要原始分辨率的图片，又不是做segmentation，可以缩小输出的尺寸，这样还能加快训练速度。

## 扩展脑洞  
**多帧预测**

可以同样的特征提取模型同时跑几帧图像，之后再concat到一起，塞到后续模型里面预测。

**三明治预测**

给网络前面帧和后面帧，让网络补出来中间帧。

**遮挡预测**

前面的都是帧间预测，也可以遮挡图片一部分给网络预测，算是帧内模型。这个我记得有好多已经完成的工作了。

  
  
后续准备试试这些脑洞吧，应该已经有很多别人的previous work了。

