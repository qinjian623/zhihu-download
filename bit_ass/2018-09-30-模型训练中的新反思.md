---
layout: default
---
# 模型训练中的新反思

 [*Link:*](https://zhuanlan.zhihu.com/p/42202641)

## 思路与线索  
在之前的一篇总结里面提到对多尺度的思考：  


[Captain Jack：数据质量的重要性与多尺度的重新思考](https://zhuanlan.zhihu.com/p/36414486)当时自己认为，网络可以传递小目标的信息进入后续的层次，即使从down sample带来的数据丢失的角度来说，可能缩小后的feature map直觉上看已经完全不能表示小目标了，但是因为不断的增加channel，小目标精确的位置信息依然会通过某一形式的编码传递到后续层次中。  
如果如上面所说，网络有这个能力可以传递小目标的精确位置信息到后续层次，我们就可以直接在最后层feature map比较小的位置重新获得检测框。这样的好处是检测网络的运行速度非常接近于一般的分类网络，运行速度起码在GPU上可以非常快了。  
当然，这样带来的结果就是检测任务需要相对简单，因为这些编码的传递都是网络负担的一部分。  
  
新的训练结果的想法依然是上面想法的继续：  


[Captain Jack：Small object fast detection](https://zhuanlan.zhihu.com/p/42013651)速度基本与分类网络一致，小目标的能力也基本具备。

但是在训练过程中，自己对这个想法又有了一些重新的认识：

* 是否能够编码和传递目标位置详细信息是存疑的
* 对于小目标来言周围的上下文信息作用巨大

  


## 数据集变化过程  
***行人车辆数据集的验证：***  
检测模型最先验证的数据集是行人和车辆，输入则是640x384 RGB。在这里的缩放依然是32倍，也就是最终的feature大小是20x12。由于feature比较小，python的循环占用时间也少了，完成Rects的获取后FPS在200FPS以上。最终测试集F1达到了0.8+，在这样的速度的前提下，这样的指标已经比较让人可以接受了，毕竟已经超出之前的预期。  
  
***红绿灯数据集的验证：***  
随后同事正在处理的红绿灯数据依然面对速度和精度都不足的情况，于是我要来数据集开始训练。简单分成两次训练来说明（实际每个分辨率都有多次训练和调整）。

1. 依然是640x384输入，32倍缩放。但是这里的训练遇到的问题，训练过程中的指标并不理想。在确认目标是否存在的分支上，预测可以达到0.8的F1。但是随后在数据集合上根据Rects进行的测试，指标则差很多。很明显是目标框的回归太差，这可能确实和细节信息丢失太多有关。而网络没有成功保存和传递好这些精确的信息。
2. 在这样的情况下，我选择加倍了输入尺寸和减少了缩放尺度。调整为1280x720输入，砍掉了ResNet18的一个缩放级别，原来预计速度会降低到80FPS，但是实际情况forward的速度基本没有变化，在速度上这是超出预期的，随后的训练就十分顺利，在前几个epochs就收敛到了0.7以上。

## 新的反思  
***网络传递微小目标的能力存疑***  
从上面训练过程来看，存在这样的一个推理：

1. 由于缩放尺寸太大，会造成目标的细节信息丢失。
2. 网络可能并不能保持和传递细节信息。

对于这一推理的反面：

1. 本身目标就十分小，即使1280x720的分辨率，目标大小也只有十几像素，换做640x384的大小，都在十个像素以内了。事实上本身就没什么信息可言。（但是，确认目标是否存在的分支上依然可以获得训练，所以并不是完全没有信息，只是精确信息没能保存）
2. Anchor选择的并不好，造成回归难度太大。最小的anchor都已经是十几像素的大小，训练难度自然更大。（但是，anchor只是负责框的比例，框的位置与anchor并没有关系，实际的结果来看，当时的目标框比例都不错，大部分情况是有漂移的偏差）
3. 接上的但是，目标框比例本身都不是太离谱，那么说明详细信息是有保存下来的，那么漂移的偏差是为什么？可能是由于w、h的预测范围和精度相对更加容易学习，而x、y的位置精度学习难度更大。
4. 网络的训练难度更大，需要更多的时间去收敛。640x384的训练过程只进行了很少次epochs，可能随着迭代次数多，网络会完成调整。（没但是）

  
***针对目标上下文的重要性***  
训练2中的现象：  
目标的检测初期的错误识别都集中在树干、金属杆，之后上方一块黑色色块一类东西。初期的目标检测其实蛮印象派的。。。大概是个样子就认为是，后续会慢慢更加纠结细节，更加精准。  
这一现象说明，网络不单单是针对目标本体的识别，也包括周边信息。尤其是周边信息有强相关性的目标，比如就是红绿灯这样的：路口位置、有灯有柱。  
  
另一个可以支持这个想法的证据是，出现过这样的现象：车辆从行人红绿灯下经过，并没有遮挡目标本体，但是目标依然丢失。可能是车辆的经过影响了目标的周边信息，造成目标的丢失。  
  
  
自己的猜想：  
小目标，由于缺少目标本体的细节信息，如果只单纯的考虑目标的几十个像素，容易与其他物体混淆，加入周边信息才可能更好的判断，减少错误。而红绿灯的好处就是周边信息是强相关的。  
所以，自己猜想，如果是类似这样的小目标，周边信息特征明显，是可以实现比较好的检测效果，即使目标本身已经不明显了，但是这必须是在训练中考虑到目标的周边信息。反之，很可能会容易出现误识别，因为模型缺少周边信息来确认这样一个小到根本看不清的物体到底属于不属于待检的目标。

